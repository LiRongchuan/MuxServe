{
  "llm-1": {
    "model_name": "/LLMCKPTs/huggyllama/llama-13b",
    "mps": [
      100,
      90
    ],
    "first_token_latency": 0.9621036103608729,
    "output_per_token_latency": 0.2187642268489366,
    "request_num": 702,
    "throughput": 7.758713599483951,
    "tokens_throughput": 2978.6718319887764,
    "prefill_avg_batches": 9.887323943661972,
    "prefill_batch_times": 71,
    "decoding_avg_batches": 380.9155172413793,
    "decoding_batch_times": 580,
    "p99[avg_latency]": 83.49024304015451,
    "p95[avg_latency]": 75.55891923383157,
    "p90[avg_latency]": 71.51373058108241,
    "p99[TTFT]": 2.4336775345800437,
    "p95[TTFT]": 1.9524063589218998,
    "p90[TTFT]": 1.7673666599448772,
    "p99[TPOT]": 1.3426146239067207,
    "p95[TPOT]": 0.4264699868003656,
    "p90[TPOT]": 0.2967101018235551,
    "origin_file": "/mnt/afs/lurunyu/data/requests_over_time_models_days_from_day55_to_day55_condense1600_N17_maxrate_26_avgrate_8_placement_requests_over_time_models_days_from_day55_to_day55_condense1600_N17_maxrate_26_avgrate_8_GPUnum32_mesh_size8_idx0_temporal_stats.json"
  },
  "llm-10": {
    "model_name": "/LLMCKPTs/huggyllama/llama-65b",
    "mps": [
      100,
      90
    ],
    "first_token_latency": 35.620229445076276,
    "output_per_token_latency": 0.17046710073995644,
    "request_num": 68,
    "throughput": 0.47132273086369775,
    "tokens_throughput": 155.09290332067795,
    "prefill_avg_batches": 1.36,
    "prefill_batch_times": 50,
    "decoding_avg_batches": 13.454166666666667,
    "decoding_batch_times": 1440,
    "p99[avg_latency]": 116.88552346337995,
    "p95[avg_latency]": 112.12131524982304,
    "p90[avg_latency]": 108.84331410845184,
    "p99[TTFT]": 72.95248999431617,
    "p95[TTFT]": 71.68297485262063,
    "p90[TTFT]": 71.03497191118262,
    "p99[TPOT]": 0.7403136272305648,
    "p95[TPOT]": 0.5261522013378275,
    "p90[TPOT]": 0.27650279303305353,
    "origin_file": "/mnt/afs/lurunyu/data/requests_over_time_models_days_from_day55_to_day55_condense1600_N17_maxrate_26_avgrate_8_placement_requests_over_time_models_days_from_day55_to_day55_condense1600_N17_maxrate_26_avgrate_8_GPUnum32_mesh_size4_idx2_temporal_stats.json"
  },
  "llm-11": {
    "model_name": "/LLMCKPTs/huggyllama/llama-30b",
    "mps": [
      100,
      90
    ],
    "first_token_latency": 25.66635147071739,
    "output_per_token_latency": 0.1785623042020935,
    "request_num": 533,
    "throughput": 3.6277675903830957,
    "tokens_throughput": 1607.039785676084,
    "prefill_avg_batches": 7.640186915887851,
    "prefill_batch_times": 214,
    "decoding_avg_batches": 164.37651122625215,
    "decoding_batch_times": 1158,
    "p99[avg_latency]": 121.0426878004305,
    "p95[avg_latency]": 114.96313953322917,
    "p90[avg_latency]": 109.1844012684077,
    "p99[TTFT]": 68.13929786668643,
    "p95[TTFT]": 66.17503758914395,
    "p90[TTFT]": 62.193572925549,
    "p99[TPOT]": 0.7536539052469713,
    "p95[TPOT]": 0.38287335044504806,
    "p90[TPOT]": 0.21780700439172873,
    "origin_file": "/mnt/afs/lurunyu/data/requests_over_time_models_days_from_day55_to_day55_condense1600_N17_maxrate_26_avgrate_8_placement_requests_over_time_models_days_from_day55_to_day55_condense1600_N17_maxrate_26_avgrate_8_GPUnum32_mesh_size4_idx1_temporal_stats.json"
  },
  "llm-12": {
    "model_name": "/LLMCKPTs/huggyllama/llama-13b",
    "mps": [
      100,
      90
    ],
    "first_token_latency": 1.0408672897629667,
    "output_per_token_latency": 0.402932120818486,
    "request_num": 163,
    "throughput": 2.2144094256866422,
    "tokens_throughput": 682.1060297809854,
    "prefill_avg_batches": 3.975609756097561,
    "prefill_batch_times": 41,
    "decoding_avg_batches": 28.478131212723657,
    "decoding_batch_times": 1006,
    "p99[avg_latency]": 63.62261682041845,
    "p95[avg_latency]": 53.16460752752237,
    "p90[avg_latency]": 48.60543649320306,
    "p99[TTFT]": 2.9677659901704634,
    "p95[TTFT]": 2.4544974807165563,
    "p90[TTFT]": 2.097953719623387,
    "p99[TPOT]": 2.554017913262356,
    "p95[TPOT]": 1.5702521534714233,
    "p90[TPOT]": 0.862841496941154,
    "origin_file": "/mnt/afs/lurunyu/data/requests_over_time_models_days_from_day55_to_day55_condense1600_N17_maxrate_26_avgrate_8_placement_requests_over_time_models_days_from_day55_to_day55_condense1600_N17_maxrate_26_avgrate_8_GPUnum32_mesh_size4_idx4_temporal_stats.json"
  },
  "llm-13": {
    "model_name": "/LLMCKPTs/huggyllama/llama-7b",
    "mps": [
      100,
      90
    ],
    "first_token_latency": 19.59804545018534,
    "output_per_token_latency": 0.2312806623715887,
    "request_num": 168,
    "throughput": 1.508119901743331,
    "tokens_throughput": 423.52136216874175,
    "prefill_avg_batches": 1.5412844036697249,
    "prefill_batch_times": 109,
    "decoding_avg_batches": 29.630890052356023,
    "decoding_batch_times": 764,
    "p99[avg_latency]": 91.68415149020478,
    "p95[avg_latency]": 71.03056764316372,
    "p90[avg_latency]": 64.75788195762225,
    "p99[TTFT]": 39.456852439704726,
    "p95[TTFT]": 37.37547744155116,
    "p90[TTFT]": 36.15950202581287,
    "p99[TPOT]": 1.260139656759178,
    "p95[TPOT]": 0.6581557571187797,
    "p90[TPOT]": 0.43939899031240154,
    "origin_file": "/mnt/afs/lurunyu/data/requests_over_time_models_days_from_day55_to_day55_condense1600_N17_maxrate_26_avgrate_8_placement_requests_over_time_models_days_from_day55_to_day55_condense1600_N17_maxrate_26_avgrate_8_GPUnum32_mesh_size4_idx2_temporal_stats.json"
  },
  "llm-14": {
    "model_name": "/LLMCKPTs/huggyllama/llama-65b",
    "mps": [
      100,
      90
    ],
    "first_token_latency": 0.8830958285945159,
    "output_per_token_latency": 0.32433839392292135,
    "request_num": 75,
    "throughput": 0.8220285409765171,
    "tokens_throughput": 295.06440468838423,
    "prefill_avg_batches": 2.4193548387096775,
    "prefill_batch_times": 31,
    "decoding_avg_batches": 30.301507537688444,
    "decoding_batch_times": 597,
    "p99[avg_latency]": 86.13904320076108,
    "p95[avg_latency]": 79.52145224244333,
    "p90[avg_latency]": 72.08076749950276,
    "p99[TTFT]": 2.305313540368155,
    "p95[TTFT]": 2.0583947386126957,
    "p90[TTFT]": 1.8262685993798076,
    "p99[TPOT]": 1.0179498255695127,
    "p95[TPOT]": 0.7930075923378086,
    "p90[TPOT]": 0.7775253792794851,
    "origin_file": "/mnt/afs/lurunyu/data/requests_over_time_models_days_from_day55_to_day55_condense1600_N17_maxrate_26_avgrate_8_placement_requests_over_time_models_days_from_day55_to_day55_condense1600_N17_maxrate_26_avgrate_8_GPUnum32_mesh_size8_idx0_temporal_stats.json"
  },
  "llm-15": {
    "model_name": "/LLMCKPTs/huggyllama/llama-7b",
    "mps": [
      100,
      90
    ],
    "first_token_latency": 1.68093024303671,
    "output_per_token_latency": 0.12843660632463946,
    "request_num": 272,
    "throughput": 5.100311323058084,
    "tokens_throughput": 1471.3648121239771,
    "prefill_avg_batches": 2.804123711340206,
    "prefill_batch_times": 97,
    "decoding_avg_batches": 55.19651741293532,
    "decoding_batch_times": 804,
    "p99[avg_latency]": 41.85035239230994,
    "p95[avg_latency]": 38.18506724235228,
    "p90[avg_latency]": 31.54891878964193,
    "p99[TTFT]": 5.6920562300618744,
    "p95[TTFT]": 5.341306032107211,
    "p90[TTFT]": 4.965120090434327,
    "p99[TPOT]": 0.49594274719671116,
    "p95[TPOT]": 0.3180244576476979,
    "p90[TPOT]": 0.2516402802637617,
    "origin_file": "/mnt/afs/lurunyu/data/requests_over_time_models_days_from_day55_to_day55_condense1600_N17_maxrate_26_avgrate_8_placement_requests_over_time_models_days_from_day55_to_day55_condense1600_N17_maxrate_26_avgrate_8_GPUnum32_mesh_size2_idx6_temporal_stats.json"
  },
  "llm-16": {
    "model_name": "/LLMCKPTs/huggyllama/llama-65b",
    "mps": [
      100,
      90
    ],
    "first_token_latency": 0.6078887378406743,
    "output_per_token_latency": 0.12760462704018527,
    "request_num": 116,
    "throughput": 1.93009505653046,
    "tokens_throughput": 619.4939581443283,
    "prefill_avg_batches": 2.577777777777778,
    "prefill_batch_times": 45,
    "decoding_avg_batches": 42.4160363086233,
    "decoding_batch_times": 661,
    "p99[avg_latency]": 50.30557869490979,
    "p95[avg_latency]": 43.704073717016726,
    "p90[avg_latency]": 42.55098202486522,
    "p99[TTFT]": 1.9591146659879002,
    "p95[TTFT]": 1.6156601542280982,
    "p90[TTFT]": 1.4793252265453338,
    "p99[TPOT]": 0.5262891593927633,
    "p95[TPOT]": 0.24704948616126116,
    "p90[TPOT]": 0.19408526885672472,
    "origin_file": "/mnt/afs/lurunyu/data/requests_over_time_models_days_from_day55_to_day55_condense1600_N17_maxrate_26_avgrate_8_placement_requests_over_time_models_days_from_day55_to_day55_condense1600_N17_maxrate_26_avgrate_8_GPUnum32_mesh_size4_idx3_temporal_stats.json"
  },
  "llm-2": {
    "model_name": "/LLMCKPTs/huggyllama/llama-13b",
    "mps": [
      100,
      90
    ],
    "first_token_latency": 1.0796630826186389,
    "output_per_token_latency": 0.24885350485389207,
    "request_num": 100,
    "throughput": 2.0107135580108757,
    "tokens_throughput": 493.6100713560899,
    "prefill_avg_batches": 2.127659574468085,
    "prefill_batch_times": 47,
    "decoding_avg_batches": 18.110016420361248,
    "decoding_batch_times": 609,
    "p99[avg_latency]": 43.07579362553751,
    "p95[avg_latency]": 34.65226823736912,
    "p90[avg_latency]": 29.340396599322567,
    "p99[TTFT]": 4.318911939248256,
    "p95[TTFT]": 3.4279156322628257,
    "p90[TTFT]": 3.1858843023628,
    "p99[TPOT]": 1.3696637902873197,
    "p95[TPOT]": 0.5866170027183903,
    "p90[TPOT]": 0.4854328737618419,
    "origin_file": "/mnt/afs/lurunyu/data/requests_over_time_models_days_from_day55_to_day55_condense1600_N17_maxrate_26_avgrate_8_placement_requests_over_time_models_days_from_day55_to_day55_condense1600_N17_maxrate_26_avgrate_8_GPUnum32_mesh_size2_idx6_temporal_stats.json"
  },
  "llm-3": {
    "model_name": "/LLMCKPTs/huggyllama/llama-13b",
    "mps": [
      100,
      90
    ],
    "first_token_latency": 2.674606482625898,
    "output_per_token_latency": 0.6014415907831823,
    "request_num": 611,
    "throughput": 9.797740510191177,
    "tokens_throughput": 2052.073409311236,
    "prefill_avg_batches": 11.528301886792454,
    "prefill_batch_times": 53,
    "decoding_avg_batches": 126.16569200779728,
    "decoding_batch_times": 513,
    "p99[avg_latency]": 57.22096081389299,
    "p95[avg_latency]": 49.77013439165428,
    "p90[avg_latency]": 42.55880443349481,
    "p99[TTFT]": 5.960844573756678,
    "p95[TTFT]": 5.468498465875164,
    "p90[TTFT]": 5.1401818482950326,
    "p99[TPOT]": 3.583996589984741,
    "p95[TPOT]": 2.315452173317317,
    "p90[TPOT]": 1.5971374066014374,
    "origin_file": "/mnt/afs/lurunyu/data/requests_over_time_models_days_from_day55_to_day55_condense1600_N17_maxrate_26_avgrate_8_placement_requests_over_time_models_days_from_day55_to_day55_condense1600_N17_maxrate_26_avgrate_8_GPUnum32_mesh_size4_idx4_temporal_stats.json"
  },
  "llm-4": {
    "model_name": "/LLMCKPTs/huggyllama/llama-7b",
    "mps": [
      100,
      90
    ],
    "first_token_latency": 2.103219599578116,
    "output_per_token_latency": 0.21323558500223966,
    "request_num": 703,
    "throughput": 6.4142582853700905,
    "tokens_throughput": 2752.0635210878427,
    "prefill_avg_batches": 9.373333333333333,
    "prefill_batch_times": 75,
    "decoding_avg_batches": 112.40972222222223,
    "decoding_batch_times": 2016,
    "p99[avg_latency]": 91.90082504811475,
    "p95[avg_latency]": 79.91088038959353,
    "p90[avg_latency]": 72.9038266670369,
    "p99[TTFT]": 5.672224989407883,
    "p95[TTFT]": 5.472840689146891,
    "p90[TTFT]": 4.9479005401246265,
    "p99[TPOT]": 1.122628941341211,
    "p95[TPOT]": 0.5937215334137961,
    "p90[TPOT]": 0.40602605232719824,
    "origin_file": "/mnt/afs/lurunyu/data/requests_over_time_models_days_from_day55_to_day55_condense1600_N17_maxrate_26_avgrate_8_placement_requests_over_time_models_days_from_day55_to_day55_condense1600_N17_maxrate_26_avgrate_8_GPUnum32_mesh_size4_idx5_temporal_stats.json"
  },
  "llm-5": {
    "model_name": "/LLMCKPTs/huggyllama/llama-13b",
    "mps": [
      100,
      90
    ],
    "first_token_latency": 14.86972901753744,
    "output_per_token_latency": 0.2551823415747973,
    "request_num": 94,
    "throughput": 0.8010968285889932,
    "tokens_throughput": 192.15244887442586,
    "prefill_avg_batches": 1.4461538461538461,
    "prefill_batch_times": 65,
    "decoding_avg_batches": 13.073027090694936,
    "decoding_batch_times": 849,
    "p99[avg_latency]": 87.95791832706807,
    "p95[avg_latency]": 69.82778982919548,
    "p90[avg_latency]": 61.244795971175655,
    "p99[TTFT]": 32.009637707029285,
    "p95[TTFT]": 29.91631298812851,
    "p90[TTFT]": 29.317771366838368,
    "p99[TPOT]": 1.4192026200826502,
    "p95[TPOT]": 0.5984611077156538,
    "p90[TPOT]": 0.45707404280500497,
    "origin_file": "/mnt/afs/lurunyu/data/requests_over_time_models_days_from_day55_to_day55_condense1600_N17_maxrate_26_avgrate_8_placement_requests_over_time_models_days_from_day55_to_day55_condense1600_N17_maxrate_26_avgrate_8_GPUnum32_mesh_size4_idx2_temporal_stats.json"
  },
  "llm-6": {
    "model_name": "/LLMCKPTs/huggyllama/llama-13b",
    "mps": [
      100,
      90
    ],
    "first_token_latency": 4.666456482051727,
    "output_per_token_latency": 0.24291954157723233,
    "request_num": 159,
    "throughput": 1.1023500680417242,
    "tokens_throughput": 276.01736420677435,
    "prefill_avg_batches": 1.9886363636363635,
    "prefill_batch_times": 88,
    "decoding_avg_batches": 23.41328413284133,
    "decoding_batch_times": 1084,
    "p99[avg_latency]": 115.42773357194866,
    "p95[avg_latency]": 90.62253844241796,
    "p90[avg_latency]": 83.52685963068159,
    "p99[TTFT]": 24.721386118040527,
    "p95[TTFT]": 9.309365191064776,
    "p90[TTFT]": 9.005852109063419,
    "p99[TPOT]": 1.3228421129970374,
    "p95[TPOT]": 0.5313713050272776,
    "p90[TPOT]": 0.41067347689902295,
    "origin_file": "/mnt/afs/lurunyu/data/requests_over_time_models_days_from_day55_to_day55_condense1600_N17_maxrate_26_avgrate_8_placement_requests_over_time_models_days_from_day55_to_day55_condense1600_N17_maxrate_26_avgrate_8_GPUnum32_mesh_size4_idx1_temporal_stats.json"
  },
  "llm-7": {
    "model_name": "/LLMCKPTs/huggyllama/llama-7b",
    "mps": [
      100,
      90
    ],
    "first_token_latency": 8.067412807263567,
    "output_per_token_latency": 0.15119508348958158,
    "request_num": 84,
    "throughput": 1.1328096234164602,
    "tokens_throughput": 341.55558728891293,
    "prefill_avg_batches": 1.68,
    "prefill_batch_times": 50,
    "decoding_avg_batches": 20.33377308707124,
    "decoding_batch_times": 758,
    "p99[avg_latency]": 68.05466880277545,
    "p95[avg_latency]": 63.19544457502661,
    "p90[avg_latency]": 54.69300399984979,
    "p99[TTFT]": 19.59744499836285,
    "p95[TTFT]": 18.575172932935878,
    "p90[TTFT]": 17.8296559205316,
    "p99[TPOT]": 0.3958767939267372,
    "p95[TPOT]": 0.30532986865908784,
    "p90[TPOT]": 0.22901083829336263,
    "origin_file": "/mnt/afs/lurunyu/data/requests_over_time_models_days_from_day55_to_day55_condense1600_N17_maxrate_26_avgrate_8_placement_requests_over_time_models_days_from_day55_to_day55_condense1600_N17_maxrate_26_avgrate_8_GPUnum32_mesh_size2_idx7_temporal_stats.json"
  },
  "llm-8": {
    "model_name": "/LLMCKPTs/huggyllama/llama-30b",
    "mps": [
      100,
      90
    ],
    "first_token_latency": 5.608916099867572,
    "output_per_token_latency": 0.22211795094102424,
    "request_num": 176,
    "throughput": 2.50086248430767,
    "tokens_throughput": 669.2791129169067,
    "prefill_avg_batches": 1.9775280898876404,
    "prefill_batch_times": 89,
    "decoding_avg_batches": 39.11241610738255,
    "decoding_batch_times": 596,
    "p99[avg_latency]": 50.785621502739374,
    "p95[avg_latency]": 46.44289596432355,
    "p90[avg_latency]": 42.17174808177165,
    "p99[TTFT]": 12.398329501608385,
    "p95[TTFT]": 12.05397607565392,
    "p90[TTFT]": 11.629498776094987,
    "p99[TPOT]": 1.6574141177892063,
    "p95[TPOT]": 0.5554130712618645,
    "p90[TPOT]": 0.37226195691129926,
    "origin_file": "/mnt/afs/lurunyu/data/requests_over_time_models_days_from_day55_to_day55_condense1600_N17_maxrate_26_avgrate_8_placement_requests_over_time_models_days_from_day55_to_day55_condense1600_N17_maxrate_26_avgrate_8_GPUnum32_mesh_size2_idx7_temporal_stats.json"
  },
  "llm-9": {
    "model_name": "/LLMCKPTs/huggyllama/llama-30b",
    "mps": [
      100,
      90
    ],
    "first_token_latency": 0.7801798470507447,
    "output_per_token_latency": 0.269979736980968,
    "request_num": 65,
    "throughput": 0.7509723237122423,
    "tokens_throughput": 189.75337607153642,
    "prefill_avg_batches": 2.3214285714285716,
    "prefill_batch_times": 28,
    "decoding_avg_batches": 15.957711442786069,
    "decoding_batch_times": 804,
    "p99[avg_latency]": 73.89603222802653,
    "p95[avg_latency]": 64.5640428093448,
    "p90[avg_latency]": 50.393683629281824,
    "p99[TTFT]": 2.8927947475194933,
    "p95[TTFT]": 2.3966909057982253,
    "p90[TTFT]": 1.8268317229077222,
    "p99[TPOT]": 0.9018665192509068,
    "p95[TPOT]": 0.7293510531724401,
    "p90[TPOT]": 0.6485648606632373,
    "origin_file": "/mnt/afs/lurunyu/data/requests_over_time_models_days_from_day55_to_day55_condense1600_N17_maxrate_26_avgrate_8_placement_requests_over_time_models_days_from_day55_to_day55_condense1600_N17_maxrate_26_avgrate_8_GPUnum32_mesh_size4_idx5_temporal_stats.json"
  },
  "throughput": 5.192178991584379,
  "request_num": 4089
}